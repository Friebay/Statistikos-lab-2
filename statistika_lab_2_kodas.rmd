---
title: "Statistikos laboratorinis darbas Nr. 2"
author: "VU"
date: "2025-03-27"
output:
  pdf_document:
    toc: true
    latex_engine: xelatex
  html_document:
    toc: true
    toc_float: true
    theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

1.  Aprašykite turimus duomenis, nurodykite duomenų šaltinį.

Duomenys atsisiųsti iš <https://github.com/valdas-v1/lithuanian-real-estate-listings>. Duomenys buvo surinkti 2024 m. vasarį iš <https://www.aruodas.lt/> puslapio. Duomenų rinkinyje yra informacija apie parduodamus ir nuomojamus butus, garažus, namus, sklypus ir patalpas.

```{r}
# Set the path to the data directory
data_dir <- "C:/Users/zabit/Documents/GitHub/Statistikos-lab-2/data"

# Get all folder names inside the data directory
folders <- list.dirs(data_dir, full.names = FALSE, recursive = FALSE)

# Print all folder names
print(folders)
```

```{r}
# Read the CSV files into a list of dataframes
csv_data_list <- list()

for (folder in folders) {
  file_path <- file.path(data_dir, folder, "all_cities_20240214.csv")
  if (file.exists(file_path)) {
    # Try reading the file
    tryCatch({
      df <- read.csv(file_path)
      csv_data_list[[folder]] <- df
      cat("Read:", folder, "with", nrow(df), "rows and", ncol(df), "columns\n")
    }, error = function(e) {
      cat("Error", folder, ":", conditionMessage(e), "\n")
    })
  }
}
```

Ieškome galimai neteisingai įvestų duomenų.

```{r}
# Remove rows with extreme prices (price > 25,000,000 or price < 20)
for (type in names(csv_data_list)) {
  if (!is.null(csv_data_list[[type]]) && "price" %in% colnames(csv_data_list[[type]])) {
    # Count rows with extreme prices
    extreme_high <- sum(csv_data_list[[type]]$price > 50000000, na.rm = TRUE)
    extreme_low <- sum(csv_data_list[[type]]$price < 20, na.rm = TRUE)
    extreme_prices <- extreme_high + extreme_low
    
    if (extreme_prices > 0) {
      # Store original row count
      original_count <- nrow(csv_data_list[[type]])
      
      # Remove rows with extreme prices, keep rows where price is within range or NA
      csv_data_list[[type]] <- csv_data_list[[type]][(csv_data_list[[type]]$price >= 20 & 
                                                     csv_data_list[[type]]$price <= 25000000) | 
                                                     is.na(csv_data_list[[type]]$price), ]
      
      # Verify how many rows were removed
      new_count <- nrow(csv_data_list[[type]])
      removed_count <- original_count - new_count
      
      cat(type, ": Removed ", removed_count, " rows with extreme prices (", extreme_high, 
          " high, ", extreme_low, " low)\n", sep="")
    } else {
      cat(type, ": No rows with extreme prices\n", sep="")
    }
  } else if (!is.null(csv_data_list[[type]])) {
    cat(type, ": No price column found\n", sep="")
  }
}
```

```{r}
# Output summary of data
cat("\nSummary of all loaded datasets:\n")
for (folder_name in names(csv_data_list)) {
  cat("\nDataset from folder:", folder_name, "\n")
  cat("Number of rows:", nrow(csv_data_list[[folder_name]]), "\n")
  cat("Number of columns:", ncol(csv_data_list[[folder_name]]), "\n")
  cat("Column names:", paste(colnames(csv_data_list[[folder_name]]), collapse = ", "), "\n")
}

# Get all unique column names across all datasets
all_columns <- unique(unlist(lapply(csv_data_list, colnames)))
unique_columns <- sort(all_columns)

# Display unique column names and count
cat("Total unique columns across all datasets:", length(unique_columns), "\n")
cat("Unique column names:", paste(unique_columns, collapse = ", "), "\n")

# Display sample values for each unique column
cat("Sample values for each unique column:\n")
for (col_name in unique_columns) {
  cat("\n", col_name, ":\n")
  found_values <- FALSE
  
  # Look for this column in each dataset
  for (dataset_name in names(csv_data_list)) {
    df <- csv_data_list[[dataset_name]]
    
    # Check if this column exists in the current dataset
    if (col_name %in% colnames(df)) {
      # Extract non-NA values
      non_na_values <- df[[col_name]][!is.na(df[[col_name]])]
      
      # If we have non-NA values
      if (length(non_na_values) > 0) {
        # Take up to 3 samples
        sample_size <- min(3, length(non_na_values))
        samples <- non_na_values[1:sample_size]
        
        # Display the samples with the dataset name
        cat("  From ", dataset_name, ": ", 
            paste(samples, collapse = ", "), 
            if(length(non_na_values) > 3) " ..." else "", "\n", sep = "")
        
        found_values <- TRUE
        break  # Only show from one dataset to keep output manageable
      }
    }
  }
  
  if (!found_values) {
    cat("  No non-NA values found in any dataset\n")
  }
}
```

```{r}
library(ggplot2)

# Real estate types to analyze
real_estate_types <- c("apartments", "houses", "land", "premises")

# Reset the plot layout
par(mfrow = c(1, 1))

price_data <- data.frame()

for (type in real_estate_types) {
  if (type %in% names(csv_data_list) && "price" %in% colnames(csv_data_list[[type]])) {
    # Extract prices and create a data frame
    temp_data <- data.frame(
      price = csv_data_list[[type]]$price,
      type = rep(type, length(csv_data_list[[type]]$price))
    )
    price_data <- rbind(price_data, temp_data)
  }
}

# Create combined box plot if we have data
if (nrow(price_data) > 0) {
  ggplot(price_data, aes(x = type, y = price, fill = type)) +
    geom_boxplot(outlier.size = 1) +
    scale_y_continuous(labels = scales::comma) +
    labs(title = "Price Distribution Across Real Estate Types",
         x = "Real Estate Type",
         y = "Price (EUR)") +
    theme_minimal() +
    theme(legend.position = "none")
}

# Create combined box plot if we have data
if (nrow(price_data) > 0) {
  ggplot(price_data, aes(x = type, y = price, fill = type)) +
    geom_boxplot(outlier.size = 1) +
    scale_y_continuous(labels = scales::comma,
                       limits = c(NA, 1000000)) + # Set the upper limit
    labs(title = "Price Distribution Across Real Estate Types",
         x = "Real Estate Type",
         y = "Price (EUR)") +
    theme_minimal() +
    theme(legend.position = "none")
}
```

```{r}

# Reset the plot layout
par(mfrow = c(1, 1))

for (type in real_estate_types) {
  if (type %in% names(csv_data_list) && "price" %in% colnames(csv_data_list[[type]])) {
    # Get price data and create a data frame
    df <- data.frame(price = csv_data_list[[type]]$price)
    
    # Create plot object with fixed deprecated features
    p <- ggplot(df, aes(x = price)) +
      geom_histogram(aes(y = after_stat(density)),
                     bins = 30, 
                     fill = "skyblue", 
                     color = "white", 
                     alpha = 0.7) +
      geom_density(color = "darkblue", linewidth = 1) + # Fixed: size -> linewidth
      labs(title = paste(toupper(type), "Price Distribution"),
           x = "Price (EUR)",
           y = "Density") +
      theme_minimal() +
      scale_x_continuous(labels = scales::comma, limits = c(0, 1000000)) +
      coord_cartesian(xlim = c(0, 1000000))
    
    # Print the plot
    print(p)
  }
}
```

2.  Išbrėžkite turimų duomenų grafikus (parinkite tinkamiausius). Manau kokių 4 užtektų

3.  Apskaičiuokite pagrindines skaitines charakteristikas kiekybiniams kintamiesiems. Mes apskaičiavome šias skaitines charakteristikas:

    Vidurkis (Mean)

    Mediana (Median)

    Moda (Mode)

    Dispersija (Variance)

    Standartinis nuokrypis (Standard deviation)

    Kvartiliai (Quartiles) - 0.25, 0.5, 0.75

    Tarpkvartilinis plotis (IQR)

    Minimumuas
    
    Maksimumas
    
    Diapazonas (Range = max - min)

    Skewness (Asimetrija) – parodo pasiskirstymo simetriškumą

    Kurtosis – parodo, ar duomenys labiau smailūs ar plokšti nei normalus pasiskirstymas

    Medianos absoliutus nuokrypis (MAD) – atsparus vidurkio vietoje naudoti

    Coeficient of Variation (CV) – santykinis dispersijos matas: SD / mean

Kiekybiniai duomenys: kaina ("price"), peržiūrų skaičius ("views_total"), būsto dydis ("area" iš apartments), žemės ploto dydis ("area_.a." iš land), build_year iš apartments, buto aukštas ("floor"), kambarių skaičius ("number_of_rooms"), plot_area, price_per_month.

```{r}
# Create a helper function to filter datasets by column name
filter_datasets_by_column <- function(data_list, column_name) {
  filtered <- data_list[sapply(data_list, function(df) column_name %in% colnames(df))]
  cat("Datasets with column", column_name, ":\n")
  print(names(filtered))
  return(filtered)
}

# List of columns to check
columns_to_check <- c(
  "price", "price_per_month", "views_total", "area", "area_.a.", 
  "build_year", "no._of_floors", "floor", "number_of_rooms", "plot_area"
)

# Create a list to store results
column_results <- list()

# Process each column and store results
for (col in columns_to_check) {
  column_results[[col]] <- filter_datasets_by_column(csv_data_list, col)
}
```

```{r}
# Helper function to calculate the mode
get_mode <- function(v) {
  v <- v[!is.na(v)]
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

# Load required packages
library(e1071)  # For skewness and kurtosis
library(knitr)  # For table formatting

# Function to calculate statistics for a specified variable across multiple datasets
calculate_statistics <- function(data_list, variable_name, target_datasets) {
  # Create an empty data frame to store our statistics
  stats_table <- data.frame(
    Dataset = character(),
    Mean = numeric(),
    Median = numeric(),
    Mode = numeric(),
    SD = numeric(),
    Q1 = numeric(),
    Q2 = numeric(),
    Q3 = numeric(),
    IQR = numeric(),
    Min = numeric(),
    Max = numeric(),
    MAD = numeric(),
    CV = numeric(),
    stringsAsFactors = FALSE
  )
  
  # Calculate statistics for each dataframe
  for (df_name in target_datasets) {
    if (df_name %in% names(data_list) && variable_name %in% colnames(data_list[[df_name]])) {
      # Show first 10 values (keep this outside the table)
      cat("Sample from the '", variable_name, "' column for ", df_name, ":\n", sep="")
      print(head(data_list[[df_name]][[variable_name]], 10))
      cat("\n")
      
      # Calculate all statistics
      var_data <- data_list[[df_name]][[variable_name]]
      mean_val <- mean(var_data, na.rm = TRUE)
      median_val <- median(var_data, na.rm = TRUE)
      mode_val <- get_mode(var_data)
      sd_val <- sd(var_data, na.rm = TRUE)
      quartiles <- quantile(var_data, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)
      iqr_val <- IQR(var_data, na.rm = TRUE)
      min_val <- min(var_data, na.rm = TRUE)
      max_val <- max(var_data, na.rm = TRUE)
      mad_val <- mad(var_data, na.rm = TRUE)
      cv_val <- (sd_val / mean_val) * 100
      
      # Add row to stats table
      stats_table <- rbind(stats_table, data.frame(
        Dataset = df_name,
        Mean = mean_val,
        Median = median_val,
        Mode = mode_val,
        SD = sd_val,
        Q1 = quartiles[1],
        Q2 = quartiles[2],
        Q3 = quartiles[3],
        IQR = iqr_val,
        Min = min_val,
        Max = max_val,
        MAD = mad_val,
        CV = cv_val
      ))
    } else {
      cat("Dataframe", df_name, "does not exist or does not have a '", variable_name, "' column.\n", sep="")
    }
  }
  
  return(stats_table)
}

# Define dataset groups
sale_datasets <- c("apartments", "garages_parking", "houses", "land", "premises")
rent_datasets <- c("apartments_rent", "house_rent", "premises_rent")
floors_datasets <- c("apartments", "apartments_rent", "house_rent", "houses", "premises", "premises_rent")
rooms_datasets <- c("apartments", "apartments_rent", "house_rent", "houses")
all_datasets <- c("apartments", "apartments_rent", "garages_parking", "garages_parking_rent", 
                "house_rent", "houses", "land", "land_rent", "premises", "premises_rent")

# Calculate statistics for price in sale datasets
price_sale_stats <- calculate_statistics(csv_data_list, "price", sale_datasets)
kable(price_sale_stats, 
      caption = "Summary Statistics for Price Across Different Real Estate Types (Sale)",
      digits = 2,  # Round to 2 decimal places
      format.args = list(big.mark = ","))  # Add thousands separator

# Calculate statistics for price in rent datasets
price_rent_stats <- calculate_statistics(csv_data_list, "price", rent_datasets)
kable(price_rent_stats, 
      caption = "Summary Statistics for Price Across Different Real Estate Types (Rent)",
      digits = 2,  # Round to 2 decimal places
      format.args = list(big.mark = ","))  # Add thousands separator

# Calculate statistics for views_total across all datasets
views_stats <- calculate_statistics(csv_data_list, "views_total", all_datasets)
kable(views_stats, 
      caption = "Summary Statistics for Total Views Across Different Real Estate Types",
      digits = 2,  # Round to 2 decimal places
      format.args = list(big.mark = ","))  # Add thousands separator


# Calculate statistics for no._of_floors
floors_stats <- calculate_statistics(csv_data_list, "no._of_floors", floors_datasets)
kable(floors_stats, 
      caption = "Summary Statistics for Number of Floors Across Different Real Estate Types",
      digits = 2,
      format.args = list(big.mark = ","))



# Calculate statistics for number_of_rooms
rooms_stats <- calculate_statistics(csv_data_list, "number_of_rooms", rooms_datasets)
kable(rooms_stats, 
      caption = "Summary Statistics for Number of Rooms Across Different Real Estate Types",
      digits = 2,
      format.args = list(big.mark = ","))
```

4.  Sudarykite dažnių lenteles kategoriniams kintamiesiems.

5.  Suformuluokite bent 6 tyrimo hipotezes iš savo duomenų rinkinio

6.  Užrašykite kokius testus parinkote savo tyrimo hipotezėms. Hipotezės turi būti skirtos skirtingų testų naudojimui. Jei reikia susikurkite naujus kintamuosius iš turimų duomenų.

7.  Patikrinkite, ar kintamieji tenkina būtinas sąlygas testų taikymui. Jei netenkina, atlikite duomenų transformacijas.

8.  Atlikite statistinį tyrimą savo suformuluotoms hipotezėms.

9.  Pateikite tyrimo atsakymą.
