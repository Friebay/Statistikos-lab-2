---
title: "Nekilnojamojo turto objektų kainų analizė Lietuvoje"
author: "VU"
date: "2025-04-17"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    latex_engine: xelatex
    fig_caption: true
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    theme: united
    fig_caption: true
    df_print: paged
    code_folding: show
  word_document:
    toc: true
    toc_depth: '3'
subtitle: Statistikos laboratorinis darbas Nr. 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,            # Rodyti kodą
  warning = FALSE,        # Nerodyti įspėjimų
  message = FALSE,        # Nerodyti pranešimų
  fig.align = "center",   # Centruoti paveikslėlius
  fig.width = 8,          # Nustatyti paveikslėlių plotį
  fig.height = 6,         # Nustatyti paveikslėlių aukštį
  out.width = "80%",      # Išvesties plotis dokumente
  dpi = 300               # Grafikų rezoliucija
)

# Pagrindinių paketų įkėlimas
library(ggplot2)
library(dplyr)
library(knitr)
library(kableExtra)
```

# Įvadas

Šiame tyrime analizuojami Lietuvos nekilnojamojo turto rinkos duomenys, siekiant nustatyti įvairius dėsningumus ir statistines priklausomybes.

# Duomenų aprašymas

Analizei naudojami duomenys buvo atsisiųsti iš [Lithuanian Real Estate Listings](https://github.com/valdas-v1/lithuanian-real-estate-listings) GitHub repozitorijos. Duomenys buvo surinkti 2024 m. vasarį iš [Aruodas.lt](https://www.aruodas.lt/) puslapio. Duomenų rinkinyje yra informacija apie parduodamus ir nuomojamus butus, garažus, namus, sklypus ir patalpas. Tyrime naudojami duomenys apima kainų, ploto, vietos ir kitų svarbių charakteristikų informaciją.

## Duomenų nuskaitymas

```{r data-reading}
# Duomenų vieta
data_dir <- "C:/Users/zabit/Documents/GitHub/Statistikos-lab-2/data"

# Gauname aplankų pavadinimus 
folders <- list.dirs(data_dir, full.names = FALSE, recursive = FALSE)

# Atspausdiname visų aplankų pavadinimus
kable(data.frame(Kategorijos = folders), 
      caption = "Nekilnojamojo turto duomenų kategorijos") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

```{r load-data}
# CSV failų nuskaitymas į sąrašą
csv_data_list <- list()

for (folder in folders) {
  file_path <- file.path(data_dir, folder, "all_cities_20240214.csv")
  if (file.exists(file_path)) {
    # Bandyti nuskaityti failą
    tryCatch({
      df <- read.csv(file_path)
      csv_data_list[[folder]] <- df
      cat("Nuskaityta:", folder, nrow(df), "eilutėmis ir", ncol(df), "stulpeliais\n")
    }, error = function(e) {
      cat("Klaida nuskaitant", folder, ":", conditionMessage(e), "\n")
    })
  }
}
```

## Duomenų patikrinimas ir išskirčių šalinimas

Prieš pradedant statistinę analizę, būtina identifikuoti ir pašalinti galimai klaidingas ar nekorektiškas reikšmes duomenyse. Nekilnojamojo turto rinkoje egzistuoja neįprastai didelių ar mažų kainų, kurios gali atsirasti dėl duomenų įvedimo klaidų, klaidingo formato ar kitų priežasčių. Tokios išskirtys gali reikšmingai paveikti statistinės analizės rezultatus.

```{r outlier-removal}
# Apibrėžiame kainų ribas išskirčių identifikavimui
min_threshold <- 20          # Minimali patikima kaina eurais
max_threshold <- 25000000    # Maksimali patikima kaina eurais

# Sukuriame rezultatų lentelę
removal_results <- data.frame(
  Kategorija = character(),
  Pašalinta_eilučių = integer(),
  Per_didelės_kainos = integer(),
  Per_mažos_kainos = integer(),
  stringsAsFactors = FALSE
)

# Tikriname ir šaliname išskirtis kiekviename duomenų rinkinyje
for (type in names(csv_data_list)) {
  if (!is.null(csv_data_list[[type]]) && "price" %in% colnames(csv_data_list[[type]])) {
    # Identifikuojame kraštutines reikšmes
    extreme_high <- sum(csv_data_list[[type]]$price > max_threshold, na.rm = TRUE)
    extreme_low <- sum(csv_data_list[[type]]$price < min_threshold, na.rm = TRUE)
    extreme_total <- extreme_high + extreme_low
    
    if (extreme_total > 0) {
      # Išsaugome pradinį eilučių skaičių
      original_count <- nrow(csv_data_list[[type]])
      
      # Filtruojame duomenis, išlaikydami tik patikimas kainas arba NA reikšmes
      csv_data_list[[type]] <- csv_data_list[[type]][
        (csv_data_list[[type]]$price >= min_threshold & 
         csv_data_list[[type]]$price <= max_threshold) | 
          is.na(csv_data_list[[type]]$price), ]
      
      # Fiksuojame rezultatus
      new_count <- nrow(csv_data_list[[type]])
      removed_count <- original_count - new_count
      
      # Pridedame rezultatus į suvestinę
      removal_results <- rbind(removal_results, data.frame(
        Kategorija = type,
        Pašalinta_eilučių = removed_count,
        Per_didelės_kainos = extreme_high,
        Per_mažos_kainos = extreme_low
      ))
    }
  }
}

# Atvaizduojame išskirčių šalinimo rezultatus
if (nrow(removal_results) > 0) {
  kable(removal_results, 
        caption = "Išskirčių šalinimo rezultatų suvestinė") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
} else {
  cat("Duomenyse nerasta kainų, kurios viršytų nustatytas ribas.")
}

# Patikriname duomenų rinkinių dydžius po valymo
data_sizes <- data.frame(
  Eilučių_skaičius = sapply(csv_data_list, nrow),
  Stulpelių_skaičius = sapply(csv_data_list, ncol)
)

kable(data_sizes, 
      caption = "Duomenų rinkinių dydžiai po išskirčių šalinimo") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Pašalintos ekstremalios kainos, kurios galėjo iškreipti vidutines reikšmes ir kitas statistines charakteristikas.

```{r}
# Output summary of data
cat("\nColumn names of all loaded datasets:\n")
for (folder_name in names(csv_data_list)) {
  cat("\nDataset from folder:", folder_name, "\n")
  cat("Column names:", paste(colnames(csv_data_list[[folder_name]]), collapse = ", "), "\n")
}

# Get all unique column names across all datasets
all_columns <- unique(unlist(lapply(csv_data_list, colnames)))
unique_columns <- sort(all_columns)

# Display unique column names and count
cat("Total unique columns across all datasets:", length(unique_columns), "\n")
cat("Unique column names:", paste(unique_columns, collapse = ", "), "\n")
```

```{r}
# Display sample values for each unique column
cat("Sample values for each unique column:\n")
for (col_name in unique_columns) {
  cat("\n", col_name, ":\n")
  found_values <- FALSE
  
  # Look for this column in each dataset
  for (dataset_name in names(csv_data_list)) {
    df <- csv_data_list[[dataset_name]]
    
    # Check if this column exists in the current dataset
    if (col_name %in% colnames(df)) {
      # Extract non-NA values
      non_na_values <- df[[col_name]][!is.na(df[[col_name]])]
      
      # If we have non-NA values
      if (length(non_na_values) > 0) {
        # Take up to 2 samples
        sample_size <- min(2, length(non_na_values))
        samples <- non_na_values[1:sample_size]
        
        # Display the samples with the dataset name
        cat("  From ", dataset_name, ": ", 
            paste(samples, collapse = ", "), 
            if(length(non_na_values) > 3) " ..." else "", "\n", sep = "")
        
        found_values <- TRUE
        break  # Only show from one dataset to keep output manageable
      }
    }
  }
  
  if (!found_values) {
    cat("  No non-NA values found in any dataset\n")
  }
}
```

2.  Išbrėžkite turimų duomenų grafikus (parinkite tinkamiausius). Manau kokių 4 užtektų

```{r}
# Reset the plot layout
par(mfrow = c(1, 1))

library(ggplot2)

for (type in c("apartments")) {
  if (type %in% names(csv_data_list) && "price" %in% colnames(csv_data_list[[type]])) {
    # Get price data and create a data frame
    df <- data.frame(price = csv_data_list[[type]]$price)
    
    # Create plot object with fixed deprecated features
    p <- ggplot(df, aes(x = price)) +
      geom_histogram(aes(y = after_stat(density)),
                     bins = 30, 
                     fill = "skyblue", 
                     color = "white", 
                     alpha = 0.7) +
      geom_density(color = "darkblue", linewidth = 1) + # Fixed: size -> linewidth
      labs(title = paste(toupper(type), "Price Distribution"),
           x = "Price (EUR)",
           y = "Density") +
      theme_minimal() +
      scale_x_continuous(labels = scales::comma, limits = c(0, 1000000)) +
      coord_cartesian(xlim = c(0, 1000000))
    
    # Print the plot
    print(p)
  }
}

# Boxplot: Area distribution for premises and premises_rent only
premises_types <- c("premises", "premises_rent")

# Create a list to store both plots
boxplot_list <- list()

for (type in premises_types) {
  if (type %in% names(csv_data_list) && "area" %in% colnames(csv_data_list[[type]])) {
    df <- csv_data_list[[type]]
    df$type <- type  # Add type as a column
    
    # Ensure area is numeric
    df$area <- as.numeric(gsub(",", ".", as.character(df$area)))
    
    # Create boxplot
    p <- ggplot(df, aes(x = type, y = area)) +
      geom_boxplot(fill = "lightgreen", outlier.color = "red", outlier.size = 2) +
      labs(title = paste("Area Distribution for", toupper(type)),
           x = "Real Estate Type",
           y = "Area (sq. m)") +
      theme_minimal() +
      scale_y_continuous(labels = scales::comma, limits = c(0, 1000)) +
      coord_cartesian(ylim = c(0, 1000))
    
    # Print the plot
    print(p)
  } else {
    cat("Dataset", type, "is not available or doesn't have 'area' column\n")
  }
}

# Scatter Plot: Price vs. Area
for (type in c("house_rent")) {
  if (!is.null(csv_data_list[[type]]) && all(c("price", "area") %in% colnames(csv_data_list[[type]]))) {
    df <- csv_data_list[[type]]
    
    # Standardize the area column: replace commas with dots and convert to numeric
    df$area <- as.numeric(gsub(",", ".", as.character(df$area)))
    
    # Create scatter plot
    p <- ggplot(df, aes(x = area, y = price)) +
      geom_point(color = "blue", alpha = 0.5) +
      labs(title = paste("Price vs. Area for", toupper(type)),
           x = "Area (sq. m)",
           y = "Price (EUR)") +
      theme_minimal() +
      scale_y_continuous(labels = scales::comma, limits = c(0, 6000)) +
      scale_x_continuous(labels = scales::comma, limits = c(0, 500))
    
    print(p)
  }
}

# Bar Chart: Frequency of Building Types for "apartments"
if ("houses" %in% names(csv_data_list) && "building_type" %in% colnames(csv_data_list[["houses"]])) {
  df <- csv_data_list[["houses"]]
  
  # Create bar chart
  p <- ggplot(df, aes(x = building_type)) +
    geom_bar(fill = "skyblue", color = "black") +
    labs(title = "Frequency of Building Types for APARTMENTS",
         x = "Building Type",
         y = "Count") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  print(p)
}
```

3.  Apskaičiuokite pagrindines skaitines charakteristikas kiekybiniams kintamiesiems. Mes apskaičiavome šias skaitines charakteristikas:

    Vidurkis (Mean)

    Mediana (Median)

    Moda (Mode)

    Dispersija (Variance)

    Standartinis nuokrypis (Standard deviation)

    Kvartiliai (Quartiles) - 0.25, 0.5, 0.75

    Minimumuas
    
    Maksimumas

Kiekybiniai duomenys: kaina ("price"), peržiūrų skaičius ("views_total"), būsto dydis ("area" iš apartments), žemės ploto dydis ("area_.a." iš land), build_year iš apartments, buto aukštas ("floor"), kambarių skaičius ("number_of_rooms"), plot_area, price_per_month.

```{r}
# Create a helper function to filter datasets by column name
filter_datasets_by_column <- function(data_list, column_name) {
  filtered <- data_list[sapply(data_list, function(df) column_name %in% colnames(df))]
  # cat("Datasets with column", column_name, ":\n")
  # print(names(filtered))
  return(filtered)
}

# List of columns to check
columns_to_check <- c(
  "price", "price_per_month", "views_total", "area", "area_.a.", 
  "build_year", "no._of_floors", "floor", "number_of_rooms", "plot_area"
)

# Create a list to store results
column_results <- list()

# Process each column and store results
for (col in columns_to_check) {
  column_results[[col]] <- filter_datasets_by_column(csv_data_list, col)
}
```

```{r}
# Simplified function to calculate summary statistics for a specified variable across multiple datasets
calculate_summary <- function(data_list, variable_name, target_datasets) {
  for (df_name in target_datasets) {
    if (df_name %in% names(data_list) && variable_name %in% colnames(data_list[[df_name]])) {
      cat("Summary for variable '", variable_name, "' in dataset '", df_name, "':\n", sep="")
      print(summary(data_list[[df_name]][[variable_name]]))
      cat("\n")
    } else {
      cat("Dataset '", df_name, "' does not exist or does not have a '", variable_name, "' column.\n", sep="")
    }
  }
}

# Define dataset groups
sale_datasets <- c("apartments", "garages_parking", "houses", "land", "premises")
rent_datasets <- c("apartments_rent", "house_rent", "premises_rent")
all_datasets <- c("apartments", "apartments_rent", "garages_parking", "garages_parking_rent", 
                "house_rent", "houses", "land", "land_rent", "premises", "premises_rent")

# Calculate summary for price in sale datasets
calculate_summary(csv_data_list, "price", sale_datasets)

# Calculate summary for price in rent datasets
calculate_summary(csv_data_list, "price", rent_datasets)

# Calculate summary for views_total across all datasets
calculate_summary(csv_data_list, "views_total", all_datasets)

# Calculate summary for no._of_floors
calculate_summary(csv_data_list, "no._of_floors", all_datasets)

# Calculate summary for number_of_rooms
calculate_summary(csv_data_list, "number_of_rooms", all_datasets)
```

4.  Sudarykite dažnių lenteles kategoriniams kintamiesiems.

5.  Suformuluokite bent 6 tyrimo hipotezes iš savo duomenų rinkinio

6.  Užrašykite kokius testus parinkote savo tyrimo hipotezėms. Hipotezės turi būti skirtos skirtingų testų naudojimui. Jei reikia susikurkite naujus kintamuosius iš turimų duomen.

7.  Patikrinkite, ar kintamieji tenkina būtinas sąlygas testų taikymui. Jei netenkina, atlikite duomenų transformacijas.

8.  Atlikite statistinį tyrimą savo suformuluotoms hipotezėms.

9.  Pateikite tyrimo atsakymą.
